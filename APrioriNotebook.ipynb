{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Necessary Imports\n",
    "- Declaring configuration type\n",
    "- Declaring constants for configuration keys (used in setting non-method accessible attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any, TypeVar, List, Callable, Self, Set, Tuple\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pandas import read_csv, to_datetime, DataFrame\n",
    "import re\n",
    "from enum import Enum\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "class HashTreeNodeType(Enum):\n",
    "    INTERNAL = 0\n",
    "    LEAF = 1\n",
    "\n",
    "# Fields for https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkConf.html#pyspark.SparkConf\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    appName: str\n",
    "    bindAddress: str\n",
    "    bindPort: str\n",
    "    masterUrl: str\n",
    "\n",
    "\n",
    "CONFIG_BIND_ADDRESS_KEY = \"spark.driver.bindAddress\"\n",
    "CONFIG_BIND_PORT_KEY = \"spark.ui.port\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the spark configuration values from the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'appName': 'APriori Example', 'masterUrl': 'local', 'bindAddress': 'localhost', 'bindPort': '4050'}\n"
     ]
    }
   ],
   "source": [
    "configuration_values: Optional[Dict[str, Any]] = None\n",
    "\n",
    "with open(\"configuration.json\", \"r\") as configuration_file:\n",
    "    configuration_values = json.loads(configuration_file.read())\n",
    "\n",
    "print(\"FAILED TO LOAD\" if configuration_values == None else configuration_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the spark configuration from the parsed json configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x2057f1f6030>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = SparkConf()\n",
    "\n",
    "spark_config: Optional[Configuration] = Configuration(**configuration_values)\n",
    "\n",
    "if spark_config == None:\n",
    "    raise ValueError(\"Must supply configuration, or keep defaults\")\n",
    "\n",
    "configuration.setAppName(spark_config.appName)\n",
    "configuration.setMaster(spark_config.masterUrl)\n",
    "configuration.set(CONFIG_BIND_ADDRESS_KEY, spark_config.bindAddress)\n",
    "configuration.set(CONFIG_BIND_PORT_KEY, spark_config.bindPort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating & Creating the SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context: Optional[SparkContext] = None\n",
    "\n",
    "if spark_context is not None:\n",
    "    spark_context.stop()\n",
    "\n",
    "spark_context = SparkContext.getOrCreate(conf=configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"baskets\" for APriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket_df = read_csv(\"./data/supermarket_sales.csv\")\n",
    "\n",
    "## Some Data Augmenting\n",
    "# Adding Month, Year, and Day columns which correspond to the respective Month/Year/Day values of the dates\n",
    "supermarket_df[\"Date\"] = to_datetime(supermarket_df[\"Date\"])\n",
    "supermarket_df[\"Hour\"] = supermarket_df[\"Time\"].map(lambda x: int(x.split(\":\")[0]))\n",
    "supermarket_df[\"Minute\"] = supermarket_df[\"Time\"].map(lambda x: int(x.split(\":\")[1]))\n",
    "\n",
    "# The goal is to form \"baskets\" from the transactions of each month, which we will use for our APriori analysis\n",
    "supermarket_df = supermarket_df.sort_values(by=\"Date\")\n",
    "\n",
    "# The current basket id\n",
    "basket_id = 1\n",
    "\n",
    "# The collection of baskets\n",
    "transactions = {}\n",
    "\n",
    "# The minute threshold\n",
    "minute_threshold = 10\n",
    "\n",
    "# The unique dates, which represent the unique day/month/year values\n",
    "unique_dates = supermarket_df[\"Date\"].unique()\n",
    "\n",
    "# Iterate over each unique date\n",
    "for each_date in unique_dates:\n",
    "\n",
    "    # Find all dates that match the current `each_date`\n",
    "    x = supermarket_df[(supermarket_df[\"Date\"].dt.year == each_date.year) & (supermarket_df[\"Date\"].dt.month == each_date.month) & (supermarket_df[\"Date\"].dt.day == each_date.day)]\n",
    "    \n",
    "    # Find all unique hours for that specific date\n",
    "    unique_hours = set([int(y) for y in x[\"Hour\"].unique()])\n",
    "\n",
    "    # Iterate over all hours that transactions occurred in that date\n",
    "    for each_hour in unique_hours:\n",
    "\n",
    "        # Find all hour transactions that match the selected hour\n",
    "        hour_transactions = x[x[\"Hour\"] == each_hour]\n",
    "\n",
    "        # Find all unique minutes within that hour\n",
    "        unique_minutes = sorted([int(y) for y in hour_transactions[\"Minute\"].unique()])\n",
    "\n",
    "        # Running set of the currently \"basket'd\" transactions\n",
    "        current_found_transaction_ids = set()\n",
    "        for i in range(len(unique_minutes) - 1):\n",
    "\n",
    "            # The current basket\n",
    "            basket = []\n",
    "\n",
    "            # The current minute\n",
    "            curr_minute = unique_minutes[i]\n",
    "\n",
    "            # All minutes that meet the threshold\n",
    "            future_minutes = list(filter(lambda x: x - curr_minute <= minute_threshold, unique_minutes[i + 1:]))\n",
    "\n",
    "            # Add current minute to the minutes to find\n",
    "            total_minutes_to_find = [curr_minute] + future_minutes\n",
    "            for each_minute in total_minutes_to_find:\n",
    "\n",
    "                # Find the record matching to the minute we are looking for, grabbing it's product name\n",
    "                records = x[x[\"Minute\"] == each_minute][\"Product line\"].to_list()\n",
    "\n",
    "                # Find the record matching to the minute we are looking for, extracting it's id to avoid double counting\n",
    "                record_ids = x[x[\"Minute\"] == each_minute].index.to_list()\n",
    "                \n",
    "                # \"extend\" the basket, which just appends all elements, but avoids duplicates\n",
    "                basket.extend([re.match(r\"\\w+\", records[i]).group(0).lower() for i in range(len(records)) if record_ids[i] not in current_found_transaction_ids])\n",
    "\n",
    "                # For each record that meets the criteria of being in the threshold and already not basket'd\n",
    "                for each_record_id in record_ids:\n",
    "                    # Add the found record id to the currently found transaction ids\n",
    "                    current_found_transaction_ids.add(each_record_id)\n",
    "            \n",
    "            # If the basket has stuff in it, then add it to the list of baskets\n",
    "            if len(basket) > 0:\n",
    "                transactions[basket_id] = basket\n",
    "                basket_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the APriori algorithm :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APriori:\n",
    "    def __init__(self):\n",
    "        self.candidates: List[T] = []\n",
    "        self.support_threshold = None\n",
    "        self.baskets: Dict[int, List[T]]\n",
    "\n",
    "    def prune_candidates(self):\n",
    "        filtered_candidates = []\n",
    "        for each_candidate_set  in self.candidates: # for each candidate that exists\n",
    "            support_count = 0\n",
    "            setted_candidate = set(each_candidate_set)\n",
    "            for each_basket in self.baskets.values(): # test against all baskets computed\n",
    "                if setted_candidate.issubset(set(each_basket)): # check if the candidate is a subset of the basket\n",
    "                    support_count += 1\n",
    "\n",
    "            if support_count >= self.support_threshold:\n",
    "                filtered_candidates.append(each_candidate_set)\n",
    "        if len(filtered_candidates) == 0:\n",
    "            raise Exception(\"No candidates meet support threshold, terminating\")\n",
    "\n",
    "        self.candidates = filtered_candidates\n",
    "\n",
    "    def extend_candidates(self):\n",
    "        new_candidates = []\n",
    "        candidates_len = range(len(self.candidates))\n",
    "        for i in candidates_len:\n",
    "            for j in candidates_len:\n",
    "                if i != j:\n",
    "                    candidate_a = self.candidates[i]\n",
    "                    candidate_b = self.candidates[j]\n",
    "                    set_a = set(candidate_a)\n",
    "                    set_b = set(candidate_b)\n",
    "                    union_a_b = set_a.union(set_b)\n",
    "                    is_valid = len(union_a_b) == len(set_a) + 1 and len(union_a_b) == len(set_b) + 1 and not list(union_a_b) in new_candidates\n",
    "\n",
    "                    if is_valid:\n",
    "                        new_candidate = set_a.union(set_b)\n",
    "                        new_candidates.append(list(new_candidate))\n",
    "\n",
    "        if len(new_candidates) == 0:\n",
    "            raise Exception(\"Cannot extend candidates further, frequent itemsets have been found\")\n",
    "        \n",
    "        self.candidates = new_candidates\n",
    "    \n",
    "    def set_candidates(self, candidates: List[T]):\n",
    "        self.candidates = candidates\n",
    "        return self\n",
    "    \n",
    "    def set_support_threshold(self, support_threshold: int):\n",
    "        self.support_threshold = support_threshold\n",
    "        return self\n",
    "    \n",
    "    def set_baskets(self, baskets: List[List[T]]):\n",
    "        self.baskets = baskets\n",
    "        return self\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                self.prune_candidates()\n",
    "                self.extend_candidates()\n",
    "            except:\n",
    "                return self.candidates\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_candidates = set()\n",
    "for each_basket in transactions.values():\n",
    "    converted_candidates.update(set(each_basket))\n",
    "\n",
    "singleton_candidates = []\n",
    "for each_item in converted_candidates:\n",
    "    singleton_candidates.append([each_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52 ms ± 92.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "apriori = APriori().set_baskets(transactions).set_candidates(singleton_candidates).set_support_threshold(9)\n",
    "apriori.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can expand and improve the complexity of APriori, by using a Hash-Tree data structure, I will go over the details further down this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTreeNode:\n",
    "    def __init__(self, branching_factor: int, hashing_function: Callable[[List[T]], int], storage_threshold: int, support_threshold: int):    \n",
    "        self.storage_threshold = storage_threshold\n",
    "        self.hashing_function = hashing_function\n",
    "        self.branching_factor = branching_factor\n",
    "        self.stored_itemsets: Set[str] = set()\n",
    "        self.support_count = 0\n",
    "        self.type = HashTreeNodeType.LEAF\n",
    "        self.children: List[Optional[Self]] = [None] * self.branching_factor\n",
    "        self.support_threshold = support_threshold\n",
    "        self.candidates_met_threshold = False\n",
    "\n",
    "    def add_itemset(self, itemset: List[T]):\n",
    "\n",
    "        if self.storage_threshold == len(self.stored_itemsets):\n",
    "            self.type = HashTreeNodeType.INTERNAL\n",
    "            cloned_itemsets = self.stored_itemsets.copy()\n",
    "            self.stored_itemsets = set()\n",
    "            self.support_count = 0\n",
    "\n",
    "            for each_itemset in cloned_itemsets:\n",
    "                self.add_itemset(each_itemset)\n",
    "\n",
    "        if self.type == HashTreeNodeType.INTERNAL:\n",
    "            found_branch = self.hashing_function(itemset) % self.branching_factor\n",
    "\n",
    "            if self.children[found_branch] is not None:\n",
    "                if self.children[found_branch].type == HashTreeNodeType.INTERNAL:\n",
    "                    self.children[found_branch].add_itemset(itemset)\n",
    "                else:\n",
    "                    self.children[found_branch].stored_itemsets.add(str(set(itemset)))\n",
    "            else:\n",
    "                self.children[found_branch] = HashTreeNode(self.branching_factor, self.hashing_function, self.storage_threshold, self.support_threshold)\n",
    "                self.children[found_branch].stored_itemsets.add(str(set(itemset)))\n",
    "        \n",
    "        else:\n",
    "            self.stored_itemsets.add(str(set(itemset)))\n",
    "    \n",
    "    def process_itemset(self, itemset: List[T]) -> Tuple[bool, Set[str]]:\n",
    "        if self.type == HashTreeNodeType.INTERNAL:\n",
    "            found_branch = self.hashing_function(itemset) % self.branching_factor\n",
    "            \n",
    "            if self.children[found_branch] is not None:\n",
    "                if self.children[found_branch].type == HashTreeNodeType.LEAF:\n",
    "                    leaf_node = self.children[found_branch]\n",
    "                    setted_itemset = set(itemset)\n",
    "                    is_in_children = any([eval(each_child) in setted_itemset for each_child in leaf_node.stored_itemsets])\n",
    "                    \n",
    "                    if is_in_children:\n",
    "                        self.children[found_branch].support_count += 1\n",
    "                        \n",
    "                        if leaf_node.support_count >= leaf_node.support_threshold and not leaf_node.candidates_met_threshold:\n",
    "                            leaf_node.candidates_met_threshold = True\n",
    "                            return (True, leaf_node.stored_itemsets)\n",
    "                        \n",
    "                    return (False, [])\n",
    "                return self.children[found_branch].process_itemset(itemset)\n",
    "        else:\n",
    "            setted_itemset = set(itemset)\n",
    "            is_in_children = any([eval(each_child).issubset(setted_itemset) for each_child in self.stored_itemsets])\n",
    "\n",
    "            if is_in_children:\n",
    "                return (True, self.stored_itemsets)\n",
    "            \n",
    "        return (False, [])\n",
    "                    \n",
    "\n",
    "class HashTree:\n",
    "    def __init__(self, branching_factor: int, hashing_function: Callable[[List[T]], int], node_storage_threshold: int, support_threshold: int):\n",
    "\n",
    "        if branching_factor is None or hashing_function is None:\n",
    "            raise Exception(\"Must define branching factor and hashing function in order to properly use the Hash-Tree data structure\")\n",
    "        \n",
    "        if branching_factor == 0:\n",
    "            raise Exception(\"Cannot have branching factor of 0\")\n",
    "\n",
    "        if node_storage_threshold <= 0:\n",
    "            raise ValueError(\"Invalid `node_storage_threshold` value\")\n",
    "        \n",
    "        if support_threshold <= 0:\n",
    "            raise ValueError(\"Invalid `support_threshold` value\")\n",
    "\n",
    "        self.branching_factor = branching_factor\n",
    "        self.hashing_function = hashing_function\n",
    "        self.root: Optional[HashTreeNode] = None\n",
    "        self.node_storage_threshold = node_storage_threshold\n",
    "        self.support_threshold = support_threshold\n",
    "\n",
    "    def add_itemset(self, itemset: List[T]):\n",
    "        if self.root is None:\n",
    "            self.root = HashTreeNode(self.branching_factor, self.hashing_function, self.node_storage_threshold, self.support_threshold)\n",
    "\n",
    "        self.root.add_itemset(itemset)\n",
    "\n",
    "    def process_itemset(self, itemset: List[T]):\n",
    "        if self.root is None:\n",
    "            return (False, [])\n",
    "        \n",
    "        return self.root.process_itemset(itemset)\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAPriori:\n",
    "    def __init__(self):\n",
    "        self.candidates: List[List[T]] = []\n",
    "        self.support_threshold = None\n",
    "        self.baskets: Dict[int, List[T]]\n",
    "        self.branching_factor = None\n",
    "        self.hashing_function = None\n",
    "        self.node_storage_threshold = None\n",
    "        self.hash_tree : Optional[HashTree] = None\n",
    "        self.candidate_supports = {}\n",
    "        \n",
    "        \n",
    "    def create_hash_tree(self) -> HashTree:\n",
    "        if self.support_threshold is None or self.branching_factor is None or self.hashing_function is None or self.node_storage_threshold is None:\n",
    "            raise ValueError(\"Invalid configuration for HashTree instantiation\")\n",
    "        \n",
    "        self.hash_tree = HashTree(self.branching_factor, self.hashing_function, self.node_storage_threshold, self.support_threshold)\n",
    "\n",
    "    def prune_candidates(self) -> Self:\n",
    "        \"\"\"\n",
    "        \"Prunes\" the existing candidate set, using the support threshold to determine whether any candidates in the current set\n",
    "        are not considered \"frequent\" or not\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the pruning step removes all existing candidates, then return the candidates before pruning, as they are the most frequent\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        filtered_candidates = []\n",
    "\n",
    "        for each_basket in self.baskets.values(): # test against all baskets computed\n",
    "            (found, candidates) = self.hash_tree.process_itemset(each_basket)\n",
    "            \n",
    "            if not found:\n",
    "                continue\n",
    "            \n",
    "            for each_candidate in candidates:\n",
    "                self.candidate_supports[str(each_candidate)] += 1\n",
    "                \n",
    "                \n",
    "        for each_candidate, each_candidate_count in self.candidate_supports.items():\n",
    "            if each_candidate_count >= self.support_threshold:\n",
    "                filtered_candidates.append(eval(each_candidate))\n",
    "\n",
    "        if len(filtered_candidates) == 0:\n",
    "            raise Exception(\"No candidates meet support threshold, terminating\")\n",
    "\n",
    "        self.candidates = filtered_candidates\n",
    "        return self\n",
    "\n",
    "    def extend_candidates(self) -> Self:\n",
    "        \"\"\"\n",
    "        Extends the candidates, extension means forming a new candidate set which we will further prune as well.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If it's impossible to further extend the candidate set\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        new_candidates = []\n",
    "        candidates_len = range(len(self.candidates))\n",
    "\n",
    "        for i in candidates_len:\n",
    "            for j in candidates_len:\n",
    "                if i != j:\n",
    "                    candidate_i = self.candidates[i]\n",
    "                    candidate_j = self.candidates[j]\n",
    "                    set_i = set(candidate_i)\n",
    "                    set_j = set(candidate_j)\n",
    "                    union_i_j = set_i.union(set_j)\n",
    "                    is_extended_itemset_valid = len(union_i_j) == len(set_i) + 1 and len(union_i_j) == len(set_j) + 1 and not list(union_i_j) in new_candidates\n",
    "\n",
    "                    if is_extended_itemset_valid:\n",
    "                        new_candidate = set_i.union(set_j)\n",
    "                        new_candidates.append(list(new_candidate))\n",
    "\n",
    "        if len(new_candidates) == 0:\n",
    "            raise Exception(\"Cannot extend candidates further, frequent itemsets have been found\")\n",
    "        \n",
    "        return self.set_candidates(new_candidates)\n",
    "    \n",
    "    def set_candidates(self, candidates: List[List[T]]) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the \"candidates\", or the itemsets which could potentially be frequent itemsets\n",
    "\n",
    "        Args:\n",
    "            candidates (List[T]): The currently computed frequent itemsets\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        self.candidates = candidates\n",
    "        self.hash_tree_candidates()\n",
    "        return self\n",
    "    \n",
    "    def hash_tree_candidates(self):\n",
    "        \n",
    "        if self.hash_tree is None:\n",
    "            raise ValueError(\"HashTree is not instantiated\")\n",
    "        \n",
    "        for each_candidate in self.candidates:\n",
    "            self.candidate_supports[str(set(each_candidate))] = 0\n",
    "            self.hash_tree.add_itemset(each_candidate)\n",
    "    \n",
    "    def set_support_threshold(self, support_threshold: int) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the \"support threshold\" for the APriori class, this is the threshold by which we consider a itemset \"frequent\" or not\n",
    "\n",
    "        Args:\n",
    "            support_threshold (int): The support threshold we apply to the candidate sets which is involved in the \"pruning\" step\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        self.support_threshold = support_threshold\n",
    "        return self\n",
    "    \n",
    "    def set_baskets(self, baskets: List[List[T]]) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the \"baskets\", or the parsed transaction database, into a list of transactions that we use to measure the\n",
    "        support value of the candidate set\n",
    "\n",
    "        Args:\n",
    "            baskets (List[List[T]]): The parsed transactions\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        self.baskets = baskets\n",
    "        return self\n",
    "    \n",
    "    def set_branching_factor(self, branching_factor: int = 5) -> Self:\n",
    "        self.branching_factor = branching_factor\n",
    "        return self\n",
    "    \n",
    "    def set_hashing_function(self, hashing_function: Callable[[List[T]], int]) -> Self:\n",
    "        self.hashing_function = hashing_function\n",
    "        return self\n",
    "    \n",
    "    def set_node_storage_threshold(self, node_storage_threshold: int = 10) -> Self:\n",
    "        self.node_storage_threshold = node_storage_threshold\n",
    "        return self\n",
    "    \n",
    "    def run(self) -> List[T]:\n",
    "        \"\"\"\n",
    "        This is the core function that runs the APriori algorithm on the dataset fields set in the instantiation of the APriori class\n",
    "\n",
    "        Returns:\n",
    "            List[T]: The frequent itemsets calculated using the APriori algorithm\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                self.prune_candidates()\n",
    "                self.create_hash_tree()\n",
    "                self.extend_candidates()\n",
    "            except Exception as error:\n",
    "                return self.candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the APriori with HashTree to work, we first must define a hashing function, branching factor, and node_storage_threshold.\n",
    "Let's do just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_factor = 10\n",
    "hashing_function = lambda x: sum([sum([ord(z) for z in y]) for y in x])\n",
    "node_storage_threshold = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m new_apriori\u001b[38;5;241m.\u001b[39mcreate_hash_tree()\n\u001b[0;32m      3\u001b[0m new_apriori\u001b[38;5;241m.\u001b[39mset_baskets(transactions)\u001b[38;5;241m.\u001b[39mset_candidates(singleton_candidates)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mnew_apriori\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[168], line 155\u001b[0m, in \u001b[0;36mEnhancedAPriori.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_hash_tree()\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextend_candidates()\n",
      "Cell \u001b[1;32mIn[168], line 33\u001b[0m, in \u001b[0;36mEnhancedAPriori.prune_candidates\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m filtered_candidates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each_basket \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaskets\u001b[38;5;241m.\u001b[39mvalues(): \u001b[38;5;66;03m# test against all baskets computed\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     (found, candidates) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_itemset\u001b[49m\u001b[43m(\u001b[49m\u001b[43meach_basket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[166], line 99\u001b[0m, in \u001b[0;36mHashTree.process_itemset\u001b[1;34m(self, itemset)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, [])\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_itemset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[166], line 47\u001b[0m, in \u001b[0;36mHashTreeNode.process_itemset\u001b[1;34m(self, itemset)\u001b[0m\n\u001b[0;32m     45\u001b[0m leaf_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren[found_branch]\n\u001b[0;32m     46\u001b[0m setted_itemset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(itemset)\n\u001b[1;32m---> 47\u001b[0m is_in_children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meach_child\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m setted_itemset \u001b[38;5;28;01mfor\u001b[39;00m each_child \u001b[38;5;129;01min\u001b[39;00m leaf_node\u001b[38;5;241m.\u001b[39mstored_itemsets])\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_in_children:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren[found_branch]\u001b[38;5;241m.\u001b[39msupport_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_apriori = EnhancedAPriori().set_support_threshold(9).set_branching_factor(10).set_hashing_function(hashing_function).set_node_storage_threshold(7)\n",
    "new_apriori.create_hash_tree()\n",
    "new_apriori.set_baskets(transactions).set_candidates(singleton_candidates)\n",
    "new_apriori.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APrioriTid:\n",
    "    def __init__(self):\n",
    "        self.candidates: List[List[T]] = []\n",
    "        self.support_threshold = None\n",
    "        self.transactions: Dict[int, List[T]] = {}\n",
    "        self.hash_tree : Optional[HashTree] = None\n",
    "        self.transaction_db: Dict[int, List[T]] = {}\n",
    "\n",
    "    def prune_candidates(self) -> Self:\n",
    "        \"\"\"\n",
    "        \"Prunes\" the existing candidate set, using the support threshold to determine whether any candidates in the current set\n",
    "        are not considered \"frequent\" or not\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the pruning step removes all existing candidates, then return the candidates before pruning, as they are the most frequent\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        filtered_candidates = []\n",
    "        for each_candidate_set  in self.candidates: # for each candidate that exists\n",
    "            support_count = 0\n",
    "            setted_candidate = set(each_candidate_set)\n",
    "\n",
    "            for each_transaction_id in self.transactions: # test against all baskets computed\n",
    "                each_transaction = self.transactions[each_transaction_id]\n",
    "                if setted_candidate.issubset(set(each_transaction)): # check if the candidate is a subset of the basket\n",
    "                    support_count += 1\n",
    "                    self.transaction_db[each_transaction_id].append(setted_candidate) # add the candidate to the list\n",
    "\n",
    "            if support_count >= self.support_threshold:\n",
    "                filtered_candidates.append(each_candidate_set)\n",
    "\n",
    "        # APrioriTid implementation\n",
    "        delete_keys = []\n",
    "        for each_key in self.transaction_db:\n",
    "            if len(self.transaction_db[each_key]) == 0:\n",
    "                delete_keys.append(each_key)\n",
    "\n",
    "        for each_delete_key in delete_keys:\n",
    "            del self.transactions[each_delete_key]\n",
    "\n",
    "            self.transaction_db[each_key] = [] # reset list\n",
    "\n",
    "        if len(filtered_candidates) == 0:\n",
    "            raise Exception(\"No candidates meet support threshold, terminating\")\n",
    "\n",
    "        self.candidates = filtered_candidates\n",
    "        return self\n",
    "\n",
    "    def extend_candidates(self) -> Self:\n",
    "        \"\"\"\n",
    "        Extends the candidates, extension means forming a new candidate set which we will further prune as well.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If it's impossible to further extend the candidate set\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        new_candidates = []\n",
    "        candidates_len = range(len(self.candidates))\n",
    "\n",
    "        for i in candidates_len:\n",
    "            for j in candidates_len:\n",
    "                if i != j:\n",
    "                    candidate_i = self.candidates[i]\n",
    "                    candidate_j = self.candidates[j]\n",
    "                    set_i = set(candidate_i)\n",
    "                    set_j = set(candidate_j)\n",
    "                    union_i_j = set_i.union(set_j)\n",
    "                    is_extended_itemset_valid = len(union_i_j) == len(set_i) + 1 and len(union_i_j) == len(set_j) + 1 and not list(union_i_j) in new_candidates\n",
    "\n",
    "                    if is_extended_itemset_valid:\n",
    "                        new_candidate = set_i.union(set_j)\n",
    "                        new_candidates.append(list(new_candidate))\n",
    "\n",
    "        if len(new_candidates) == 0:\n",
    "            raise Exception(\"Cannot extend candidates further, frequent itemsets have been found\")\n",
    "        \n",
    "        self.candidates = new_candidates\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def set_candidates(self, candidates: List[List[T]]) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the \"candidates\", or the itemsets which could potentially be frequent itemsets\n",
    "\n",
    "        Args:\n",
    "            candidates (List[T]): The currently computed frequent itemsets\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        self.candidates = candidates\n",
    "        return self\n",
    "    \n",
    "    def set_support_threshold(self, support_threshold: int) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the \"support threshold\" for the APriori class, this is the threshold by which we consider a itemset \"frequent\" or not\n",
    "\n",
    "        Args:\n",
    "            support_threshold (int): The support threshold we apply to the candidate sets which is involved in the \"pruning\" step\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        self.support_threshold = support_threshold\n",
    "        return self\n",
    "    \n",
    "    def set_baskets(self, baskets: Dict[int, List[T]]) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the \"baskets\", or the parsed transaction database, into a list of transactions that we use to measure the\n",
    "        support value of the candidate set\n",
    "\n",
    "        Args:\n",
    "            baskets (List[List[T]]): The parsed transactions\n",
    "\n",
    "        Returns:\n",
    "            Self: The mutated APriori instance\n",
    "        \"\"\"\n",
    "        self.transactions = baskets\n",
    "\n",
    "        for each_transaction_id in baskets:\n",
    "            self.transaction_db[each_transaction_id] = set()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def run(self) -> List[T]:\n",
    "        \"\"\"\n",
    "        This is the core function that runs the APriori algorithm on the dataset fields set in the instantiation of the APriori class\n",
    "\n",
    "        Returns:\n",
    "            List[T]: The frequent itemsets calculated using the APriori algorithm\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                self.prune_candidates()\n",
    "                self.extend_candidates()\n",
    "            except:\n",
    "                return self.candidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
