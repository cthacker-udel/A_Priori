{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Necessary Imports\n",
    "- Declaring configuration type\n",
    "- Declaring constants for configuration keys (used in setting non-method accessible attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any, TypeVar, List, Callable, Self, Set\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pandas import read_csv, to_datetime, DataFrame\n",
    "import re\n",
    "from enum import Enum\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "class HashTreeNodeType(Enum):\n",
    "    INTERNAL = 0\n",
    "    LEAF = 1\n",
    "\n",
    "# Fields for https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkConf.html#pyspark.SparkConf\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    appName: str\n",
    "    bindAddress: str\n",
    "    bindPort: str\n",
    "    masterUrl: str\n",
    "\n",
    "\n",
    "CONFIG_BIND_ADDRESS_KEY = \"spark.driver.bindAddress\"\n",
    "CONFIG_BIND_PORT_KEY = \"spark.ui.port\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the spark configuration values from the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'appName': 'APriori Example', 'masterUrl': 'local', 'bindAddress': 'localhost', 'bindPort': '4050'}\n"
     ]
    }
   ],
   "source": [
    "configuration_values: Optional[Dict[str, Any]] = None\n",
    "\n",
    "with open(\"configuration.json\", \"r\") as configuration_file:\n",
    "    configuration_values = json.loads(configuration_file.read())\n",
    "\n",
    "print(\"FAILED TO LOAD\" if configuration_values == None else configuration_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the spark configuration from the parsed json configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x1eecdda9010>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = SparkConf()\n",
    "\n",
    "spark_config: Optional[Configuration] = Configuration(**configuration_values)\n",
    "\n",
    "if spark_config == None:\n",
    "    raise ValueError(\"Must supply configuration, or keep defaults\")\n",
    "\n",
    "configuration.setAppName(spark_config.appName)\n",
    "configuration.setMaster(spark_config.masterUrl)\n",
    "configuration.set(CONFIG_BIND_ADDRESS_KEY, spark_config.bindAddress)\n",
    "configuration.set(CONFIG_BIND_PORT_KEY, spark_config.bindPort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating & Creating the SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context: Optional[SparkContext] = None\n",
    "\n",
    "if spark_context is not None:\n",
    "    spark_context.stop()\n",
    "\n",
    "spark_context = SparkContext.getOrCreate(conf=configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"baskets\" for APriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket_df = read_csv(\"./data/supermarket_sales.csv\")\n",
    "\n",
    "## Some Data Augmenting\n",
    "# Adding Month, Year, and Day columns which correspond to the respective Month/Year/Day values of the dates\n",
    "supermarket_df[\"Date\"] = to_datetime(supermarket_df[\"Date\"])\n",
    "supermarket_df[\"Hour\"] = supermarket_df[\"Time\"].map(lambda x: int(x.split(\":\")[0]))\n",
    "supermarket_df[\"Minute\"] = supermarket_df[\"Time\"].map(lambda x: int(x.split(\":\")[1]))\n",
    "\n",
    "# The goal is to form \"baskets\" from the transactions of each month, which we will use for our APriori analysis\n",
    "supermarket_df = supermarket_df.sort_values(by=\"Date\")\n",
    "\n",
    "# The current basket id\n",
    "basket_id = 1\n",
    "\n",
    "# The collection of baskets\n",
    "baskets = {}\n",
    "\n",
    "# The minute threshold\n",
    "minute_threshold = 10\n",
    "\n",
    "# The unique dates, which represent the unique day/month/year values\n",
    "unique_dates = supermarket_df[\"Date\"].unique()\n",
    "\n",
    "# Iterate over each unique date\n",
    "for each_date in unique_dates:\n",
    "\n",
    "    # Find all dates that match the current `each_date`\n",
    "    x = supermarket_df[(supermarket_df[\"Date\"].dt.year == each_date.year) & (supermarket_df[\"Date\"].dt.month == each_date.month) & (supermarket_df[\"Date\"].dt.day == each_date.day)]\n",
    "    \n",
    "    # Find all unique hours for that specific date\n",
    "    unique_hours = set([int(y) for y in x[\"Hour\"].unique()])\n",
    "\n",
    "    # Iterate over all hours that transactions occurred in that date\n",
    "    for each_hour in unique_hours:\n",
    "\n",
    "        # Find all hour transactions that match the selected hour\n",
    "        hour_transactions = x[x[\"Hour\"] == each_hour]\n",
    "\n",
    "        # Find all unique minutes within that hour\n",
    "        unique_minutes = sorted([int(y) for y in hour_transactions[\"Minute\"].unique()])\n",
    "\n",
    "        # Running set of the currently \"basket'd\" transactions\n",
    "        current_found_transaction_ids = set()\n",
    "        for i in range(len(unique_minutes) - 1):\n",
    "\n",
    "            # The current basket\n",
    "            basket = []\n",
    "\n",
    "            # The current minute\n",
    "            curr_minute = unique_minutes[i]\n",
    "\n",
    "            # All minutes that meet the threshold\n",
    "            future_minutes = list(filter(lambda x: x - curr_minute <= minute_threshold, unique_minutes[i + 1:]))\n",
    "\n",
    "            # Add current minute to the minutes to find\n",
    "            total_minutes_to_find = [curr_minute] + future_minutes\n",
    "            for each_minute in total_minutes_to_find:\n",
    "\n",
    "                # Find the record matching to the minute we are looking for, grabbing it's product name\n",
    "                records = x[x[\"Minute\"] == each_minute][\"Product line\"].to_list()\n",
    "\n",
    "                # Find the record matching to the minute we are looking for, extracting it's id to avoid double counting\n",
    "                record_ids = x[x[\"Minute\"] == each_minute].index.to_list()\n",
    "                \n",
    "                # \"extend\" the basket, which just appends all elements, but avoids duplicates\n",
    "                basket.extend([re.match(r\"\\w+\", records[i]).group(0).lower() for i in range(len(records)) if record_ids[i] not in current_found_transaction_ids])\n",
    "\n",
    "                # For each record that meets the criteria of being in the threshold and already not basket'd\n",
    "                for each_record_id in record_ids:\n",
    "                    # Add the found record id to the currently found transaction ids\n",
    "                    current_found_transaction_ids.add(each_record_id)\n",
    "            \n",
    "            # If the basket has stuff in it, then add it to the list of baskets\n",
    "            if len(basket) > 0:\n",
    "                baskets[basket_id] = basket\n",
    "                basket_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the APriori algorithm :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APriori:\n",
    "    def __init__(self):\n",
    "        self.candidates: List[T] = []\n",
    "        self.support_threshold = None\n",
    "        self.baskets: Dict[int, List[T]]\n",
    "\n",
    "    def prune_candidates(self):\n",
    "        filtered_candidates = []\n",
    "        for each_candidate_set  in self.candidates: # for each candidate that exists\n",
    "            support_count = 0\n",
    "            setted_candidate = set(each_candidate_set)\n",
    "            for each_basket in self.baskets.values(): # test against all baskets computed\n",
    "                if setted_candidate.issubset(set(each_basket)): # check if the candidate is a subset of the basket\n",
    "                    support_count += 1\n",
    "\n",
    "            if support_count >= self.support_threshold:\n",
    "                filtered_candidates.append(each_candidate_set)\n",
    "        if len(filtered_candidates) == 0:\n",
    "            raise Exception(\"No candidates meet support threshold, terminating\")\n",
    "\n",
    "        self.candidates = filtered_candidates\n",
    "\n",
    "    def extend_candidates(self):\n",
    "        new_candidates = []\n",
    "        candidates_len = range(len(self.candidates))\n",
    "        for i in candidates_len:\n",
    "            for j in candidates_len:\n",
    "                if i != j:\n",
    "                    candidate_a = self.candidates[i]\n",
    "                    candidate_b = self.candidates[j]\n",
    "                    set_a = set(candidate_a)\n",
    "                    set_b = set(candidate_b)\n",
    "                    union_a_b = set_a.union(set_b)\n",
    "                    is_valid = len(union_a_b) == len(set_a) + 1 and len(union_a_b) == len(set_b) + 1 and not list(union_a_b) in new_candidates\n",
    "\n",
    "                    if is_valid:\n",
    "                        new_candidate = set_a.union(set_b)\n",
    "                        new_candidates.append(list(new_candidate))\n",
    "\n",
    "        if len(new_candidates) == 0:\n",
    "            raise Exception(\"Cannot extend candidates further, frequent itemsets have been found\")\n",
    "        \n",
    "        self.candidates = new_candidates\n",
    "    \n",
    "    def set_candidates(self, candidates: List[T]):\n",
    "        self.candidates = candidates\n",
    "        return self\n",
    "    \n",
    "    def set_support_threshold(self, support_threshold: int):\n",
    "        self.support_threshold = support_threshold\n",
    "        return self\n",
    "    \n",
    "    def set_baskets(self, baskets: List[List[T]]):\n",
    "        self.baskets = baskets\n",
    "        return self\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                self.prune_candidates()\n",
    "                self.extend_candidates()\n",
    "            except:\n",
    "                return self.candidates\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_candidates = set()\n",
    "for each_basket in baskets.values():\n",
    "    converted_candidates.update(set(each_basket))\n",
    "\n",
    "singleton_candidates = []\n",
    "for each_item in converted_candidates:\n",
    "    singleton_candidates.append([each_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 ms ± 122 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "apriori = APriori().set_baskets(baskets).set_candidates(singleton_candidates).set_support_threshold(9)\n",
    "apriori.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can expand and improve the complexity of APriori, by using a Hash-Tree data structure, I will go over the details further down this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTreeNode:\n",
    "    def __init__(self, branching_factor: int, hashing_function: Callable[[List[T]], int], storage_threshold: int):\n",
    "        self.storage_threshold = storage_threshold\n",
    "        self.stored_itemsets: List[Set[T]] = []\n",
    "        self.type = HashTreeNodeType.LEAF\n",
    "        self.children: List[Optional[Self]] = [None] * self.branching_factor\n",
    "        self.hashing_function = hashing_function\n",
    "        self.branching_factor = branching_factor\n",
    "\n",
    "    def add_itemset(self, itemset: List[T]):\n",
    "\n",
    "        if self.storage_threshold == len(self.stored_itemsets):\n",
    "            self.type = HashTreeNodeType.INTERNAL\n",
    "            cloned_itemsets = self.stored_itemsets[:]\n",
    "            self.stored_itemsets = []\n",
    "\n",
    "            for each_itemset in cloned_itemsets:\n",
    "                self.add_itemset(each_itemset)\n",
    "\n",
    "        if self.type == HashTreeNodeType.INTERNAL:\n",
    "            found_branch = self.hashing_function(itemset) % self.branching_factor\n",
    "\n",
    "            if self.children[found_branch] is not None:\n",
    "                if self.children[found_branch].type == HashTreeNodeType.INTERNAL:\n",
    "                    self.children[found_branch].add_itemset(itemset)\n",
    "                else:\n",
    "                    self.children[found_branch].stored_itemsets.append(set(itemset))\n",
    "            else:\n",
    "                self.children[found_branch] = HashTreeNode(self.branching_factor, self.hashing_function, self.storage_threshold)\n",
    "                self.children[found_branch].stored_itemsets.append(set(itemset))\n",
    "\n",
    "    def check_itemset(self, itemset: List[T]):\n",
    "        found_branch = self.hashing_function(itemset) % self.branching_factor\n",
    "\n",
    "        if self.children[found_branch] is not None:\n",
    "            if self.children[found_branch].type == HashTreeNodeType.LEAF:\n",
    "                return set(itemset) in self.children[found_branch].stored_itemsets\n",
    "            \n",
    "            return self.children[found_branch].check_itemset(itemset)\n",
    "                    \n",
    "\n",
    "class HashTree:\n",
    "    def __init__(self, branching_factor: int, hashing_function: Callable[[List[T]], int], node_storage_threshold: int):\n",
    "\n",
    "        if branching_factor is None or hashing_function is None:\n",
    "            raise Exception(\"Must define branching factor and hashing function in order to properly use the Hash-Tree data structure\")\n",
    "        \n",
    "        if branching_factor == 0:\n",
    "            raise Exception(\"Cannot have branching factor of 0\")\n",
    "\n",
    "        self.branching_factor = branching_factor\n",
    "        self.hashing_function = hashing_function\n",
    "        self.root: Optional[HashTreeNode] = None\n",
    "        self.node_storage_threshold = node_storage_threshold\n",
    "\n",
    "    def add_itemset(self, itemset: List[T]):\n",
    "        if self.root is None:\n",
    "            self.root = HashTreeNode(self.branching_factor, self.hashing_function, self.node_storage_threshold)\n",
    "\n",
    "        self.root.add_itemset(itemset)\n",
    "\n",
    "    def check_itemset(self, itemset: List[T]):\n",
    "        if self.root is None:\n",
    "            return False\n",
    "        \n",
    "        return self.root.check_itemset(itemset)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAPriori:\n",
    "    def __init__(self):\n",
    "        self.candidates: List[List[T]] = []\n",
    "        self.support_threshold = None\n",
    "        self.baskets: Dict[int, List[T]]\n",
    "        self.hash_tree : Optional[HashTree] = None\n",
    "\n",
    "    def prune_candidates(self):\n",
    "        filtered_candidates = []\n",
    "        for each_candidate_set  in self.candidates: # for each candidate that exists\n",
    "            support_count = 0\n",
    "            setted_candidate = set(each_candidate_set)\n",
    "            for each_basket in self.baskets.values(): # test against all baskets computed\n",
    "                if setted_candidate.issubset(set(each_basket)): # check if the candidate is a subset of the basket\n",
    "                    support_count += 1\n",
    "\n",
    "            if support_count >= self.support_threshold:\n",
    "                filtered_candidates.append(each_candidate_set)\n",
    "        if len(filtered_candidates) == 0:\n",
    "            raise Exception(\"No candidates meet support threshold, terminating\")\n",
    "\n",
    "        self.candidates = filtered_candidates\n",
    "\n",
    "    def extend_candidates(self):\n",
    "        new_candidates = []\n",
    "        candidates_len = range(len(self.candidates))\n",
    "        for i in candidates_len:\n",
    "            for j in candidates_len:\n",
    "                if i != j:\n",
    "                    candidate_a = self.candidates[i]\n",
    "                    candidate_b = self.candidates[j]\n",
    "                    set_a = set(candidate_a)\n",
    "                    set_b = set(candidate_b)\n",
    "                    union_a_b = set_a.union(set_b)\n",
    "                    is_valid = len(union_a_b) == len(set_a) + 1 and len(union_a_b) == len(set_b) + 1 and not list(union_a_b) in new_candidates\n",
    "\n",
    "                    if is_valid:\n",
    "                        new_candidate = set_a.union(set_b)\n",
    "                        new_candidates.append(list(new_candidate))\n",
    "\n",
    "        if len(new_candidates) == 0:\n",
    "            raise Exception(\"Cannot extend candidates further, frequent itemsets have been found\")\n",
    "        \n",
    "        self.candidates = new_candidates\n",
    "    \n",
    "    def set_candidates(self, candidates: List[T]):\n",
    "        self.candidates = candidates\n",
    "        return self\n",
    "    \n",
    "    def set_support_threshold(self, support_threshold: int):\n",
    "        self.support_threshold = support_threshold\n",
    "        return self\n",
    "    \n",
    "    def set_baskets(self, baskets: List[List[T]]):\n",
    "        self.baskets = baskets\n",
    "        return self\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                self.prune_candidates()\n",
    "                self.extend_candidates()\n",
    "            except:\n",
    "                return self.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.36 ms ± 143 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "new_apriori = EnhancedAPriori().set_baskets(baskets).set_candidates(singleton_candidates).set_support_threshold(9)\n",
    "new_apriori.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
